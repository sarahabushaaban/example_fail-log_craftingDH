<h2>Week 4 Fail Log</h2>

<h3>Exercise 1</h3>

$ curl http://archive.org/stream/diplomaticcorre33statgoog/diplomaticcorre33statgoog_djvu.txt > texas.txt 
<ul> 
<li> curl: downloads txt file</li>
<li> >: inputs results in txt file called texas.txt</li>
<li>$ nano texas.txt: opens nano text file.</li>
<li> to make a selection, ctrl+shift+6 to set a starting point</li>
<li> hit the down arrow to highlight multiple lines of text to the bottom</li>
<li> hit ctrl+k to cut the text when done.</li>
</ul>

<h4>RegExr.com</h4>
changed expression to (.+\1<to\~1) - this substitutes to ensure ~ before every line.</li>
sed -r -i.bak 's/(.+\bto\b.+)/~\1/g' texas.txt
<ul>
<li> -r: extended regex </li>
<li>-i.bak: makes backup of original </li>
<li>- ’s/old-pattern/newpattern/g’: how we find and switch what we’re looking for. (g: globally, everywhere in the file)</li>
</ul>


$ ls to ensure new file has been created
$ nano texas.txt to see the difference


$ grep '~' texas.txt > index.txt
<ul>
<li>finds all the lines that have a ~ in them, writes them to a new file called index.txt</li>
<li>$ nano index.txt: to view the condensed list</li>
</ul>

$ sed -r -i.bak 's/(,)( [0-9]{4})(.+)/\2/g' index.txt 
<ul><li>Replaces pattern</li></ul>

$ sed -r -i.bak 's/~//g' index.txt
<ul><li> Removes tildes</li></ul>

$ sed -r -i.bak 's/(\b to \b)/,/g' index.txt
<ul><li> Separates senders and recipients </li></ul>

$ grep -r ".+,.+,.+," index.txt
<ul><li> finds all the lines with more than 2 commas</li></ul>

$ cp index.txt cleaned-correspondence.csv
<ul><li> Makes a copy as a CSV file</li></ul>

These next few steps was where I had the most difficulty. I spent almost an hour trying to figure out where I went wrong. 
I had initially input sed -r -i.bak ’s/(,)([0-9]{4})(.+)/\2/g’ index.txt to remove the comma and everything after ‘year’ and continued on with the next few steps as normal. What I didn’t realize is the importance of adding the space before the query. 
After some frustration, and tracking back my errors, I input the correct code and everything went smoothly. It was very rewarding to finally get the 13 results that Dr. Graham spoke about on Regex, as opposed to the hundreds that I had initially come up with. 

<h3>Exercise 2</h3>
Exercise 2 was a lot more simple and I did not face any difficulties with following the instructions. The only time I ran into any issue
was easily resolved by checking Slack and seeing what my classmates had done in similar situations. 

<h4>Open Refine</h4>
<ul>
<li>Create project -> Import CSV file from previous exercise (cleaned-correspondence.csv)</li>
<li>For both sender and receiver, show text facet, then click on cluster for each and group (or merge) the items that got lost in translation together</li>
<li>Click sender and receiver arrows, edit cells>common transforms>trim leading and trailing whitespace</li>
<li>Export to get file back as CSV file</li>
<li>Renamed sender and receiver columns to source and target</li>
<li>Make sure to click CSV (comma-seperated-values) to ensure data gets converted properly</li>
<li>Run through Palladio</li>

<h3>Further Comments</h3>
I still need to get better at time management because I feel like these tasks would have been a lot less stressful if I had a decent
amount of time to get the work done. I have also come to the realization that not only does Via Rail wifi not work for these digital endeavours,
but (of course) neither does airplane wifi. Definitely not airplane wifi. 

